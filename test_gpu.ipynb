{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPViqzpOWgHhpYdgl6pvSGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuliaFavaro/cmepda/blob/main/test_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "FCvxk1kVzO6Y",
        "outputId": "a37c6973-89a8-4a35-e48a-208c8ee70daa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2441c892235f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sn5raW_0Afb",
        "outputId": "6c42bc31-1dbd-4867-aa07-e7f2eac5dba5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp310-cp310-linux_x86_64.whl size=661265 sha256=8c04a416250c4cfebb96f5ca87c0730ff50fabc4e717b42a63e10eafdc556051\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/7b/06/82a395a243fce00035dea9914d92bbef0013401497d849f8bc\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2023.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda"
      ],
      "metadata": {
        "id": "fRIK3Lky0QRO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0QdAtW_0ar-",
        "outputId": "c968cce3-d3df-4567-8bb1-af55e8f2be23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52hW1kYc09ed",
        "outputId": "99ba88c0-3471-4324-cae9-7d8d8ba574d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 30 13:45:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLgCpOYv1VkI",
        "outputId": "c9f52586-da5d-4a17-8710-9c11ac298e3e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch ciao"
      ],
      "metadata": {
        "id": "hf_DFBlB1m3G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ciao"
      ],
      "metadata": {
        "id": "QwLq7Wwa1sf3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycuda import autoinit\n",
        "from pycuda.tools import DeviceData\n",
        "specs = DeviceData()\n",
        "print ('Max threads per block = '+str(specs.max_threads))\n",
        "print ('Warp size ='+str(specs.warp_size))\n",
        "print ('Warps per MP ='+str(specs.warps_per_mp))\n",
        "print ('Thread Blocks per MP ='+str(specs.thread_blocks_per_mp))\n",
        "print ('Registers ='+str(specs.registers))\n",
        "print ('Shared memory ='+ str(specs.shared_memory))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3lrQG772Aya",
        "outputId": "2e2d5541-1348-4fbd-8197-c926955df6e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max threads per block = 1024\n",
            "Warp size =32\n",
            "Warps per MP =64\n",
            "Thread Blocks per MP =8\n",
            "Registers =65536\n",
            "Shared memory =49152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile VecAdd.cu\n",
        "# include <stdio.h>\n",
        "# include <cuda_runtime.h>\n",
        "// CUDA Kernel\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
        "{\n",
        "int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "if (i<numElements){\n",
        "  C[i] = A[i] + B[i];}\n",
        "}\n",
        "/**\n",
        "* Host main routine\n",
        "*/\n",
        "int main(void)\n",
        "{\n",
        "int numElements = 15;\n",
        "size_t size = numElements * sizeof(float);\n",
        "printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
        "float a[numElements],b[numElements],c[numElements];\n",
        "float *a_gpu,*b_gpu,*c_gpu;\n",
        "cudaMalloc((void **)&a_gpu, size);\n",
        "cudaMalloc((void **)&b_gpu, size);\n",
        "cudaMalloc((void **)&c_gpu, size);\n",
        "for (int i=0;i<numElements;++i ){\n",
        "a[i] = i*i;\n",
        "b[i] = i;\n",
        "}\n",
        "// Copy the host input vectors A and B in host memory to the device input vectors in device memory\n",
        "printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "cudaMemcpy(a_gpu, a, size, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(b_gpu, b, size, cudaMemcpyHostToDevice);\n",
        "// Launch the Vector Add CUDA Kernel\n",
        "int threadsPerBlock = 256;\n",
        "int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", (blocksPerGrid threadsPerBlock));\n",
        "vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(a_gpu, b_gpu, c_gpu,numElements);\n",
        "// Copy the device result vector in device memory to the host result vector in host memory.\n",
        "printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
        "cudaMemcpy(c, c_gpu, size, cudaMemcpyDeviceToHost);\n",
        "for (int i=0;i<numElements;++i ){\n",
        "  printf(\"%f \\n\",c[i]);\n",
        "}\n",
        "// Free device global memory\n",
        "cudaFree(a_gpu);\n",
        "cudaFree(b_gpu);\n",
        "cudaFree(c_gpu);\n",
        "printf(\"Done\\n\");\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE9KLiDg2s2p",
        "outputId": "22902255-7dcc-4ec4-a1af-b6bd731f541a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting VecAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o VecAdd VecAdd.cu -arch=compute_35 -code=sm_35"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqpN3uVj3HXb",
        "outputId": "8050d83e-7671-475c-9095-7afdb017daf4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'sm_35', and 'sm_37' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\u001b[01m\u001b[0m\u001b[01mVecAdd.cu(34)\u001b[0m: \u001b[01;31merror\u001b[0m: expected a \")\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mVecAdd.cu(34)\u001b[0m: \u001b[01;35mwarning\u001b[0m #224-D: the format string requires additional arguments\n",
            "\n",
            "1 error detected in the compilation of \"VecAdd.cu\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW WE START WITH PYTHON"
      ],
      "metadata": {
        "id": "r6ZqbOUU5Gt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first we import the modules we need"
      ],
      "metadata": {
        "id": "3SrBA-yK5P6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycuda import autoinit"
      ],
      "metadata": {
        "id": "QrFa5fqI5CWq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycuda import gpuarray\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LEoP8CbP5TIk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aux = range(15)\n",
        "a = np.array(aux).astype(np.float32)\n",
        "b = (a*a).astype(np.float32)\n",
        "c = np.zeros(len(aux)).astype(np.float32)"
      ],
      "metadata": {
        "id": "ZGkCOtt55XQ2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_gpu = gpuarray.to_gpu(a)\n",
        "b_gpu = gpuarray.to_gpu(b)\n",
        "c_gpu = gpuarray.to_gpu(c)"
      ],
      "metadata": {
        "id": "jEy1apbB5Y3r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_gpu=a_gpu+b_gpu"
      ],
      "metadata": {
        "id": "JSHvpZ445cKV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdcrkBAC6FfL",
        "outputId": "94a63db5-f65c-47c2-a006-6b25ca4e19c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   2.,   6.,  12.,  20.,  30.,  42.,  56.,  72.,  90., 110.,\n",
              "       132., 156., 182., 210.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOU CAN IMPLEMENT THE SAME OPERATION ON EACH ELEMENT OF THE VECTORS"
      ],
      "metadata": {
        "id": "03525nP76fYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycuda.elementwise import ElementwiseKernel\n",
        "myCudaFunc = ElementwiseKernel(arguments = \"float *a, float *b, float *c\",\n",
        "operation = \"c[i] = a[i]+b[i]\", #you can online write operations that are one line\n",
        "name = \"mySumK\")"
      ],
      "metadata": {
        "id": "0UOEycYc6bW3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myCudaFunc(a_gpu,b_gpu,c_gpu)\n",
        "c_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaXNL4or6riL",
        "outputId": "19ab85aa-56bd-4000-b8d1-453cdff1e1e0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   2.,   6.,  12.,  20.,  30.,  42.,  56.,  72.,  90., 110.,\n",
              "       132., 156., 182., 210.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVEN MORE GENERAL PROCEDURE"
      ],
      "metadata": {
        "id": "ToF3YaCF7Xhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycuda.compiler import SourceModule"
      ],
      "metadata": {
        "id": "RW3Vfflc6vbC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cudaCode = open(\"VecAdd.cu\",\"r\")\n",
        "myCUDACode = cudaCode.read() #extraction of the code"
      ],
      "metadata": {
        "id": "7N6F2V4X7Wki"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myCode = SourceModule(myCUDACode) #compilation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "fE1RwI638jzC",
        "outputId": "2b4f8044-a4b1-4e47-d29e-a19a3b388268"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CompileError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCompileError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-dac18d36b929>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyCode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyCUDACode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#compilation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         cubin = compile(\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mnvcc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs, target)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-I\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompile_plain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile_plain\u001b[0;34m(source, options, keep, nvcc, cache_dir, target)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise CompileError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"nvcc compilation of %s failed\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcu_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mcmdline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCompileError\u001b[0m: nvcc compilation of /tmp/tmpwzx5t0nz/kernel.cu failed\n[command: nvcc --cubin -arch sm_75 -I/usr/local/lib/python3.10/dist-packages/pycuda/cuda kernel.cu]\n[stderr:\nkernel.cu(15): warning #2949-D: function \"main\" cannot be declared in a linkage-specification\n\nkernel.cu(36): error: expected a \")\"\n\nkernel.cu(36): warning #224-D: the format string requires additional arguments\n\n1 error detected in the compilation of \"kernel.cu\".\n]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importedKernel = myCode.get_function(\"vectorAdd\") #execution by importing it on Python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "RXb0oehi8mrR",
        "outputId": "b703dff9-9fce-4c97-86fc-87273f60f396"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-aee5e5fdb865>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportedKernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vectorAdd\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#execution on pYthon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'myCode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nThreadsPerBlock = 256\n",
        "nBlockPerGrid = 1\n",
        "nGridsPerBlock = 1"
      ],
      "metadata": {
        "id": "iBaxO_Tf9GjO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_gpu.set(c)\n",
        "c_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58Iyra139ogL",
        "outputId": "bfceaf0a-0fd0-4bd6-8ded-22ffb7df20bb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importedKernel(a_gpu.gpudata, b_gpu.gpudata, c_gpu.gpudata,block=(nThreadsPerBlock,nBlockPerGrid,nGridsPerBlock))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "NMiikBqq9qRJ",
        "outputId": "658260ae-95d8-480b-8f51-d500d43cd72a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-c01e6ce0eb07>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportedKernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnThreadsPerBlock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnBlockPerGrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnGridsPerBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'importedKernel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptQoYmb59yf6",
        "outputId": "e0c4d39e-6f99-4add-e588-22a0f15a2fe5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y1FyanzJ90LL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}